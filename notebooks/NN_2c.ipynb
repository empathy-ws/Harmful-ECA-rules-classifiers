{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN_DiscreteFeature.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"UgzD9F-vWatj"},"source":["from numpy import array\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.utils.class_weight import compute_class_weight\n","from keras.models import Sequential\n","from keras.models import Model\n","from keras.layers import Input\n","import torch\n","import pandas as pd\n","import numpy as np\n","from sklearn import preprocessing\n","from sklearn.model_selection import StratifiedKFold\n","from numpy import array\n","from numpy import asarray\n","from numpy import zeros\n","from keras.utils.np_utils import to_categorical\n","from keras.utils.vis_utils import plot_model\n","import matplotlib.pyplot as plt\n","import keras.backend as K\n","from itertools import product"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def getModel():\n","  input2 = Input(shape=(4,))\n","  dense_layer_1 = Dense(50, activation='tanh')(input2)\n","  dense_layer_2 = Dense(20, activation='tanh')(dense_layer_1)\n","  output = Dense(4, activation='softmax')(dense_layer_2)\n","\n","  return Model(inputs=input2, outputs=output)"],"metadata":{"id":"m9OduoC0-an2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def weighted_categorical_crossentropy(weights):\n","    \"\"\"\n","    A weighted version of keras.objectives.categorical_crossentropy\n","\n","    Variables:\n","        weights: numpy array of shape (C,) where C is the number of classes\n","\n","    Usage:\n","        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n","        loss = weighted_categorical_crossentropy(weights)\n","        model.compile(loss=loss,optimizer='adam')\n","    \"\"\"\n","\n","    weights = K.variable(weights)\n","\n","    def loss(y_true, y_pred):\n","        # scale predictions so that the class probas of each sample sum to 1\n","        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n","        # clip to prevent NaN's and Inf's\n","        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n","        # calc\n","        loss = y_true * K.log(y_pred) * weights\n","        loss = -K.sum(loss, -1)\n","        return loss\n","\n","    return loss"],"metadata":{"id":"_p3aaFoAII1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NJbC88QibeLr"},"source":["train_path = 'Training_set.csv'\n","\n","# Read the dataset\n","col_names = ['triggerTitle','triggerChannelTitle','actionChannelTitle','actionTitle','title', 'desc', 'target']\n","train_final = pd.read_csv(train_path,skiprows=1,sep=',',names=col_names,encoding = \"ISO-8859-1\")\n","\n","del train_final['title']\n","del train_final['desc']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SXaDPbZ7btdD"},"source":["# label_encoder object knows how to understand word labels.\n","label_encoder = preprocessing.LabelEncoder()\n","\n","# Encode labels in column 'species'.\n","train_final['triggerTitle'] = label_encoder.fit_transform(train_final['triggerTitle'])\n","train_final['triggerChannelTitle'] = label_encoder.fit_transform(train_final['triggerChannelTitle'])\n","train_final['actionChannelTitle'] = label_encoder.fit_transform(train_final['actionChannelTitle'])\n","train_final['actionTitle'] = label_encoder.fit_transform(train_final['actionTitle'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-KhN_SpHbxWR"},"source":["X_train = train_final.drop('target', axis=1)\n","\n","y_train = train_final['target']"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_path = 'Test_set.csv'\n","\n","# Read the dataset\n","col_names = ['triggerTitle','triggerChannelTitle','actionChannelTitle','actionTitle','title', 'desc', 'target']\n","test_final = pd.read_csv(test_path,skiprows=1,sep=';',names=col_names,encoding = \"ISO-8859-1\")"],"metadata":{"id":"NF12BJKx6WHp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del test_final['title']\n","del test_final['desc']\n","\n","# label_encoder object knows how to understand word labels.\n","label_encoder = preprocessing.LabelEncoder()\n","\n","# Encode labels in column 'species'.\n","test_final['triggerTitle'] = label_encoder.fit_transform(test_final['triggerTitle'])\n","test_final['triggerChannelTitle'] = label_encoder.fit_transform(test_final['triggerChannelTitle'])\n","test_final['actionChannelTitle'] = label_encoder.fit_transform(test_final['actionChannelTitle'])\n","test_final['actionTitle'] = label_encoder.fit_transform(test_final['actionTitle'])"],"metadata":{"id":"xdEQ4EQA6zu2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test = test_final.drop('target', axis=1)\n","\n","y_test = test_final['target']"],"metadata":{"id":"ydDSJfig6_NB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)"],"metadata":{"id":"ePdo57v4-ha3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# STRATIFIES K-FOLD CROSS VALIDATION { 4-fold }\n","\n","splits = 4\n","\n","# Create StratifiedKFold object.\n","skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=1)\n","\n","class_weights_list = []\n","\n","for train_index, test_index in skf.split(X_train, y_train):\n","    count = count + 1\n","    x_train_fold, x_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n","    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n","\n","    #compute the class weights\n","    class_weights = compute_class_weight('balanced', np.unique(y_train_fold),y = np.ravel(y_train_fold))\n","\n","    class_weights_list.append(class_weights)\n","\n","    ncce = weighted_categorical_crossentropy(weights=np.array(class_weights))\n","\n","    model = getModel()\n","\n","    model.compile(loss=ncce, optimizer='adam', metrics=['acc'])\n","\n","    model.fit(x_train_fold, y_train_fold, batch_size=16, epochs=30, verbose=1)\n","\n","    score = model.evaluate(x_test_fold, y_test_fold, verbose=0)\n","\n","    print(\"Accuracy Validation: %.2f%%\" % (score[1]*100))"],"metadata":{"id":"DB8IPUiM94C4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ncce = weighted_categorical_crossentropy(weights=np.array(class_weights_list[best_class_weight]))"],"metadata":{"id":"VAR-MPYIIYOs"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"atIgq5QonBqE"},"source":["model = getModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8SJJfx1nu5n"},"source":["model.compile(loss=ncce, optimizer='adam', metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wHbNKNYpoGM1"},"source":["history = model.fit(X_train, y_train, batch_size=16, epochs=30, verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L7lVsOBioXif"},"source":["score = model.evaluate(X_test, y_test, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmdBEDK2_Ufh"},"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","\n","y_pred = model.predict(X_test)\n","\n","y_pred_clean = np.zeros_like(y_pred)\n","for idx, i in enumerate(np.argmax(y_pred,axis=1)):\n","    y_pred_clean[idx][i] = 1\n","\n","print(classification_report(y_test, y_pred_clean))"],"execution_count":null,"outputs":[]}]}